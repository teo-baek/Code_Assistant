# ì›¹ í™”ë©´ ë©”ì¸ íŒŒì¼

import streamlit as st
import os
from streamlit_agraph import agraph, Node, Edge, Config

from brain_manager import BrainManager
from translator import LanguageTranslator
from architect import DevelopmentArchitect
from code_indexer import CodebaseIndexer
from rag_agent import AgenticBrain

from graph_manager import CodeGraphManager
from langchain_community.embeddings import HuggingFaceBgeEmbeddings
from langchain_community.vectorstores import Chroma

class CodeAssistantUI:
    """
    ì›¹ í™”ë©´ì˜ ëª¨ë“  ë²„íŠ¼ê³¼ ê¸°ëŠ¥ì„ ë°°ì¹˜í•˜ê³  ì‚¬ìš©ìì™€ ì†Œí†µí•˜ëŠ” í´ë˜ìŠ¤
    ì‚¬ìš©ìê°€ AIì˜ ìƒê°ì„ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•˜ê³ , ì½”ë“œë¥¼ ì§ì ‘ ìˆ˜ì •/ìŠ¹ì¸í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤
    """
    def __init__(self):
        # ê¸°ë³¸ ì„œë²„ ì£¼ì†Œì™€ ì„¤ì •ê°’ì„ ì •í•¨
        self.OLLAMA_URL = "http://localhost:11434"
        self.DB_PATH = "./chroma_db"
        self.EMBED_MODEL = "BAAI/bge-small-en-v1.5"
        self.NEO4J_URI = "bolt://localhost:7687"        # Neo4j ì£¼ì†Œ

        self.brain_mgr = BrainManager(self.OLLAMA_URL)
        self.architect = DevelopmentArchitect()
        self.graph_mgr = CodeGraphManager(self.NEO4J_URI, "neo4j", "password")

    def show_graph_viz(self, file_name):
        """
        Neo4j ë°ì´í„°ë¥¼ ì½ì–´ì™€ì„œ íŠ¹ì • íŒŒì¼ì˜ ì˜í–¥ ë²”ìœ„ë¥¼ ê·¸ë˜í”„ ê·¸ë¦¼ìœ¼ë¡œ ë³´ì—¬ì¤Œ
        """
        st.subheader(f"'{file_name}' ê´€ë ¨ ì˜ì¡´ì„± ì§€ë„")

        # Neo4jì—ì„œ ê´€ê³„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
        relations = self.graph_mgr.get_context_map(file_name)

        nodes = []
        edges = []

        # ì¤‘ì‹¬ ë…¸ë“œ ì¶”ê°€
        nodes.append(Node(id=file_name, label= file_name, size= 25, color= "#005088"))

        for rel in relations:
            parts = rel.split(" --")
            neighbor = parts[1].split("-- ")[1]
            rel_type = parts[1].split("(")[1].split(")")[0]

            # ì´ì›ƒ ì ê³¼ ì—°ê²° ì„ ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
            nodes.append(Node(id= neighbor, label= neighbor, size= 15, color="#11CAA0"))
            edges.append(Edge(source= file_name, target= neighbor, label= rel_type))
        
        # ê·¸ë˜í”„ ì„¤ì •
        config = Config(width= 800, height= 400, directed= True, nodeHighlightBehavior= True, highlightColor= "#F3F0DF", collapsible= True)

        # í™”ë©´ì— ê·¸ë˜í”„ë¥¼ ê·¸ë¦¼
        agraph(nodes= nodes, edges= edges, config= config)

    def run(self):
        """ì›¹ í™”ë©´ì„ êµ¬ì„±í•˜ê³  í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•¨"""
        st.set_page_config(page_title= "GrowCode", layout= "wide")
        st.title("ğŸš€ GrowCode")
        
        # 1. ë¡œê·¸ì¸ 
        if "user_id" not in st.session_state:
            st.session_state.user_id = st.text_input("ì‚¬ìš©ì IDë¥¼ ì…ë ¥í•˜ê³  ì—”í„°ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
            if not st.session_state.user_id: st.stop()
            st.rerun()
        
        # 2. ì‚¬ì´ë“œë°” - ì„¤ì •
        with st.sidebar:
            st.header("âš™ï¸ í™˜ê²½ ì„¤ì •")
            # ë‚´ ì»´í“¨í„°ì˜ Ollama ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜´
            models = self.brain_mgr.get_available_models()
            selected_model = st.selectbox("ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ", models if models else ["ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"])

            # ë‹µë³€ ë°›ì„ ì–¸ì–´ ì„ íƒ
            selected_lang = st.selectbox("ë‹µë³€ ì–¸ì–´ ì„ íƒ", ["Korean", "English", "Japanese", "Chinese"])

            # ê°œë°œí•  ê¸°ìˆ  ìŠ¤íƒ ì„ íƒ
            selected_stack = st.selectbox("ê°œë°œ ê¸°ìˆ  ìŠ¤íƒ ì„ íƒ", ["Streamlit", "React", "Flutter", "Flast", "HTML/CSS", "Java", "JavaScript"])

            st.divider()
            if st.button("ê·¸ë˜í”„ DB ì´ˆê¸°í™”"):
                self.graph_mgr.reset_graph()
                st.toast("Neo4j ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ë©”ì¸ í™”ë©´: 2ë¶„í•  (ì™¼ìª½: ì±„íŒ…/ì‹œê°í™”, ì˜¤ë¥¸ìª½: ì½”ë“œ ë¦¬ë·°)
            col_chat, col_review = st.columns([1, 1])

            with col_chat:
                st.subheader("GrowCode")
                if "messages" not in st.session_state: st.session_state.messages = []
                for msg in st.session_state.messages:
                    with st.chat_message(msg["role"]): st.markdown(msg["content"])
                
                if prompt := st.chat_input("ì‘ì—…ì„ ì§€ì‹œí•˜ì„¸ìš”"):
                    st.session_state.messages.append({"role": "user", "content": prompt})
                    st.rerun()
            
            # ì§ˆë¬¸ì´ ìƒˆë¡œ ë“¤ì–´ì™”ì„ ë•Œì˜ ì²˜ë¦¬ ë¡œì§
            if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
                user_prompt = st.session_state.messages[-1]["content"]

                # 1. ë²ˆì—­ ë° ê²€ìƒ‰ ì¤€ë¹„
                translator = LanguageTranslator(selected_model, self.OLLAMA_URL)
                en_query = translator.translate(user_prompt, "English")

                db_dir = os.path.join(self.DB_PATH, st.session_state.user_id, "default_project")
                if os.path.exists(db_dir):

            st.subheader("í”„ë¡œì íŠ¸ ì§€ì‹ ì¶”ê°€")
            p_name = st.text_input("í”„ë¡œì íŠ¸ ë³„ëª…")
            p_path = st.text_input("í´ë” ì‹¤ì œ ê²½ë¡œ")
            if st.button("ì§€ì‹ ì €ì¥ ì‹œì‘"):
                indexer = CodebaseIndexer(self.DB_ROOT, self.EMBED_MODEL)
                count = indexer.index_project(p_path, st.session_state.user_id, p_name)
                st.success(f"{count} ê°œì˜ ì§€ì‹ ì¡°ê° ì €ì¥ ì™„ë£Œ")

        # 3. ì±„íŒ… í™”ë©´
        if "messages" not in st.session_state: st.session_state.messages = []
        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]): st.markdown(msg["content"])
        
        # 4. ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"): st.markdown(prompt)

            # AIê°€ ë‹µë³€ì„ ì¤€ë¹„í•˜ëŠ” ê³¼ì •
            with st.chat_message("assistant"):
                # (1) ë²ˆì—­ ì¤€ë¹„: ì‚¬ìš©ì ì§ˆë¬¸ì„ ì˜ì–´ë¡œ ë²ˆì—­
                translator = LanguageTranslator(selected_model, self.OLLAMA_URL)
                en_query = translator.translate(prompt, "English")
                st.caption(f"ì¶”ë¡ ìš© ë²ˆì—­: {en_query}")

                # (2) DB ì—°ê²°: ì§€ì •ëœ ì§€ì‹ì„ ì°¾ì„ ì¤€ë¹„
                db_dir = os.path.join(self.DB_PATH, st.session_state.user_id, "default_project")        # ì˜ˆì‹œ default_project
                if os.path.exists(db_dir):
                    embed_ai = HuggingFaceBgeEmbeddings(model_name= self.EMBED_MODEL)
                    vector_db = Chroma(persist_directory= db_dir, embedding_function=embed_ai)
                    retriever = vector_db.as_retriever(search_kwargs= {"k": 5})

                    # (3) ì—ì´ì „íŠ¸ ì‹¤í–‰: ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•œ ì§€ì‹ ê²€ìƒ‰ ë° ì¶”ë¡ 
                    brain = AgenticBrain(selected_model, self.OLLAMA_URL, retriever)
                    flow = brain.build_workflow()

                    # ì„¤ê³„ìë¡œë¶€í„° í•´ë‹¹ ê¸°ìˆ ì— ë§ëŠ” ì „ë¬¸ ì§€ì¹¨ì„ ê°€ì ¸ì˜´
                    sys_prompt = self.architect.get_system_prompt(selected_stack)

                    with st.spinner("ìƒê°í•˜ëŠ” ì¤‘"):
                        # ì‚¬ê³  íë¦„ ì‹¤í–‰
                        final_state = flow.invoke({
                            "question": en_query,
                            "system_prompt": sys_prompt,
                            "stack": selected_stack
                        })
                        en_answer = final_state["answer"]

                        # (4) ì¬ë²ˆì—­: AIì˜ ë‹µë³€ì„ ì‚¬ìš©ì ì–¸ì–´ë¡œ ë²ˆì—­
                        final_answer = translator.translate(en_answer, selected_lang)
                        st.markdown(final_answer)

                        # ëŒ€í™” ê¸°ë¡ì— ì €ì¥
                        st.session_state.messages.append({"role": "assistant", "content": final_answer})
                else:
                    st.error("í•™ìŠµëœ í”„ë¡œì íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ë¨¼ì € í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")

if __name__ == "__main__":
    app = CodeAssistantUI()
    app.run()